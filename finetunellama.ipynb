{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e818f7-1c11-475f-a323-1f5b8a256514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 18 16:13:19 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   32C    P8    13W / 140W |      1MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bce1d3-e239-46cb-9e48-a81a91d20922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q datasets bitsandbytes einops wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ecf5894-756b-4e89-a36d-8e1cf3113979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.43.2\n",
      "  Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.2) (2.1.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.2) (1.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.2) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.43.2) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->bitsandbytes==0.43.2) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.40.2\n",
      "    Uninstalling bitsandbytes-0.40.2:\n",
      "      Successfully uninstalled bitsandbytes-0.40.2\n",
      "Successfully installed bitsandbytes-0.43.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.43.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef326e0c-ba87-4f97-b7d7-2ea1091a5137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7eb31185d4e4404be51acc6d0fb9728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0def4e8-e7a6-4771-8edf-492854df78d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = 'nisaar/Articles_Constitution_3300_Instruction_Set'\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7157190-4b3b-4214-8e09-2dc95973cc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Identify and summarize the key legal issues in the provided case.',\n",
       " 'input': 'Case Citation: Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278. The case revolves around the termination of employment of the respondents by the appellant without assigning any reason by invoking Rule 9(i) of the service rules. The respondents challenged the termination orders and the validity of Rule 9(i) in the High Court under Article 226. The Division Bench of the High Court struck down Rule 9(i) as arbitrary and violative of Article 14. The appellant filed appeals in the Supreme Court against the High Court judgment.',\n",
       " 'output': \"The key legal issues in the case Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr. are as follows: 1. The first issue is whether a government company falls under the definition of 'State' as per Article 12 of the Indian Constitution. This is important as the constitutional protections against arbitrary state action apply to 'State' entities. 2. The second issue is the constitutional validity of Rule 9(i) that allows termination of service without reason. The respondents challenged this rule as arbitrary and violative of the right to equality under Article 14 of the Constitution. 3. The third issue is the application of principles of natural justice and constitutional protections in contractual relationships, particularly in employment contracts of state entities. 4. The fourth issue is the impact of arbitrary termination of employment on the right to life and livelihood under Article 21 of the Constitution. 5. The final issue is the scope of judicial review of state action in contractual matters, particularly in the context of employment relationships.\",\n",
       " 'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify and summarize the key legal issues in the provided case.\\n\\n### Input:\\nCase Citation: Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278. The case revolves around the termination of employment of the respondents by the appellant without assigning any reason by invoking Rule 9(i) of the service rules. The respondents challenged the termination orders and the validity of Rule 9(i) in the High Court under Article 226. The Division Bench of the High Court struck down Rule 9(i) as arbitrary and violative of Article 14. The appellant filed appeals in the Supreme Court against the High Court judgment.\\n\\n### Response:'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5a401c-f2a5-4a23-87e7-f9c8b25bd3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'prompt'],\n",
      "    num_rows: 3311\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db875030-4aad-47ba-b8b6-6d22e55a372e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming `dataset` is your Dataset object\n",
    "dataset = dataset.map(lambda example: {'text': example['prompt'] + example['output']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c911f45-61bc-4a89-87d2-95e192faf474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'text'],\n",
       "    num_rows: 3311\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7bee6c-af1c-444d-bec4-659f3d41d1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "model_name = \"TinyPixel/Llama-2-7B-bf16-sharded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b235ed-9dcf-4986-bf0c-b4721c157366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1a8725-a78f-4c2e-934d-f27b063de5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 16:27:44.175145: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-18 16:27:44.211695: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-18 16:27:44.211760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-18 16:27:44.212976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 16:27:44.220335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-18 16:27:45.466819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71604aa3fbb64bde84ba2e791f1b3962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a82a20-566a-4dd1-87e5-47c5720b74b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9541e3-595d-4a24-ac6c-fa4ff4ded7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eca32ce-39e6-49e2-a1b6-a17622d1ace1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a858c91-6666-4af0-9aa2-a65cc9566e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6544bd5-39a2-4382-8269-d6ebf060dee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"./results_fff\"\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = 2\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 1\n",
    "num_train_epochs = 4\n",
    "logging_steps = 1\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 20\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccd32ee-8169-4531-a17f-83a885bdad56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01200373-ea5d-4b29-9af9-76c5eb0c74a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f616ef7-73bb-4b7e-8ba1-c803c2562913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2775c9e-692b-4093-a1d6-4976421f0104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_466/2529246835.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9afcbf71d749a28646a1cf715b5cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/3311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7188b26ed07142d79579b4c9f5dfae53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/3311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-18 16:28:37,693] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3119173-77ec-4d18-b57c-e41c49f01712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d272ec6d-7446-430f-8fd3-b7aadfe9a272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20250218_163112-swd5uale</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface/runs/swd5uale' target=\"_blank\">./results_fff</a></strong> to <a href='https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface' target=\"_blank\">https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface/runs/swd5uale' target=\"_blank\">https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface/runs/swd5uale</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:47, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.086100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.1490951359272004, metrics={'train_runtime': 182.9461, 'train_samples_per_second': 0.219, 'train_steps_per_second': 0.109, 'total_flos': 1037135611748352.0, 'train_loss': 1.1490951359272004})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd75c20dc90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd75c359bd0, execution_count=19 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd75c60ad90, raw_cell=\"trainer.train()\" store_history=True silent=False shell_futures=True cell_id=d272ec6d-7446-430f-8fd3-b7aadfe9a272> result=TrainOutput(global_step=20, training_loss=1.1490951359272004, metrics={'train_runtime': 182.9461, 'train_samples_per_second': 0.219, 'train_steps_per_second': 0.109, 'total_flos': 1037135611748352.0, 'train_loss': 1.1490951359272004})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cd485b-6c86-4be9-bc6a-a49aed33c39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd75c20dc90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd753cb9d90, raw_cell=\"model_to_save = trainer.model.module if hasattr(tr..\" store_history=True silent=False shell_futures=True cell_id=10cd485b-6c86-4be9-bc6a-a49aed33c39e>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd75c20dc90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fd750921dd0, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd753cb9d90, raw_cell=\"model_to_save = trainer.model.module if hasattr(tr..\" store_history=True silent=False shell_futures=True cell_id=10cd485b-6c86-4be9-bc6a-a49aed33c39e> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bea44e2-201b-4789-8fc8-08386a24fff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fd75c20dc90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fd75c0cf950, raw_cell=\"import wandb\n",
      "wandb.finish()\" store_history=True silent=False shell_futures=True cell_id=3bea44e2-201b-4789-8fc8-08386a24fff0>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▂▃▃▃▄▅▄▄▅▅▅▆▇▆█▇▆</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>▅▃▅▅▁▃▅▃▁▄▂▃▁▅█▁▃▄▄▂</td></tr><tr><td>train/mean_token_accuracy</td><td>▄▅▂▃▅▅▂▆▄▃▇▄█▁▁█▃▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1037135611748352.0</td></tr><tr><td>train/epoch</td><td>0.01208</td></tr><tr><td>train/global_step</td><td>20</td></tr><tr><td>train/grad_norm</td><td>0.15816</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0861</td></tr><tr><td>train/mean_token_accuracy</td><td>0.73268</td></tr><tr><td>train_loss</td><td>1.1491</td></tr><tr><td>train_runtime</td><td>182.9461</td></tr><tr><td>train_samples_per_second</td><td>0.219</td></tr><tr><td>train_steps_per_second</td><td>0.109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">./results_fff</strong> at: <a href='https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface/runs/swd5uale' target=\"_blank\">https://wandb.ai/rjnavneetsgr29-delhi-technological-university/huggingface/runs/swd5uale</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250218_163112-swd5uale/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "360361e4-3f4d-4e8d-8a4a-e21a4829514c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:79: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'TinyPixel/Llama-2-7B-bf16-sharded' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lora_config = LoraConfig.from_pretrained('outputs')\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7aae44d-6f97-47e0-a2d0-0a4647dd783b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnalyze and explain the legal reasoning behind the judgment in the given case.\\n\\n### Input:\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\\n\\n### Response:The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1d0f21-65ef-4d6e-ae6b-3f8cbe724a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "998aa6bd-8e68-43a3-b3f6-eb3f49948927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = dataset['text'][0]\n",
    "device = \"cuda:0\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d28d6a4-2d57-4d0b-b8f5-52b20b1d26db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Analyze and explain the legal reasoning behind the judgment in the given case.\n",
      "\n",
      "### Input:\n",
      "Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\n",
      "\n",
      "### Response:The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21.\n",
      "\n",
      "### Instruction:\n",
      "Analyze and explain the legal reasoning behind the judgment in the given case.\n",
      "\n",
      "### Input:\n",
      "M. Nagaraj vs Union of India, 2006 AIR 1\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8309ba43-38b0-435c-a905-8e97d11711e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): LlamaForCausalLM(\n",
      "          (model): LlamaModel(\n",
      "            (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "            (layers): ModuleList(\n",
      "              (0-31): 32 x LlamaDecoderLayer(\n",
      "                (self_attn): LlamaAttention(\n",
      "                  (q_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                  (v_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                )\n",
      "                (mlp): LlamaMLP(\n",
      "                  (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                  (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                  (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "                  (act_fn): SiLU()\n",
      "                )\n",
      "                (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "                (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "              )\n",
      "            )\n",
      "            (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb9812-8c01-4d56-815a-ac41508deb24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
